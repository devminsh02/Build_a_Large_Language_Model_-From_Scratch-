{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10945b9",
   "metadata": {},
   "source": [
    "Chapter2\n",
    "----------\n",
    "텍스트 토큰화 하기\n",
    "데이터셋 다운로드(\"The Verdict\" - Edith Wharton )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b740f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the-verdict.txt', <http.client.HTTPMessage at 0x21a873b13a0>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "url = (\"https://raw.githubusercontent.com/rickiepark/\"\n",
    "       \"llm-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    "       \"the-verdict.txt\")\n",
    "file_path = \"the-verdict.txt\"\n",
    "urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a81eb0",
   "metadata": {},
   "source": [
    "Code 2-1 처음 99개 문자 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49ef382f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 문자 개수:  20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "print(\"총 문자 개수: \", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d791f71f",
   "metadata": {},
   "source": [
    "텍스트를 토큰 리스트로 분할 ->re.split사용(문자열을 쪼개는 함수)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efd9e3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello,', ' ', 'world.', ' ', 'This,', ' ', 'is', ' ', 'a', ' ', 'test']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text =\"Hello, world. This, is a test\"\n",
    "#r'\\s'가 아닌 r'(\\s)'을 사용해서 공백도 출력 결과에 나옴\n",
    "result = re.split(r'(\\s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044543e",
   "metadata": {},
   "source": [
    "공백, 쉼표, 마침표도 분할하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf1e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, world. This, is a test']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text =\"Hello, world. This, is a test\"\n",
    "#공백('\\s')과 쉼표,마침표도 분할([,.])\n",
    "result = re.split(r'([,.]/s)', text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342a688d",
   "metadata": {},
   "source": [
    "중복된 공백 문자 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45637e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, world. This, is a test']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "text =\"Hello, world. This, is a test\"\n",
    "'''\n",
    "중복된 공백 문자 제거\n",
    "item에서 빈 문자열은 False로 간주함\n",
    "-> strip() 이후 내용이 남아 있으면 True: 남김\n",
    "내용이 없으면 False: 버림\n",
    "'''\n",
    "result = [item for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "905f3437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, world. Is this--a test?\"\n",
    "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5066c8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9235\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
    "preprocess = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa389c69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'HAD', ' ', 'always', ' ', 'thought', ' ', 'Jack', ' ', 'Gisburn', ' ', 'rather', ' ', 'a', ' ', 'cheap', ' ', 'genius', '--', 'though', ' ', 'a', ' ', 'good', ' ', 'fellow', ' ', 'enough', '--']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168e443",
   "metadata": {},
   "source": [
    "Section2.3\n",
    "------------\n",
    "\n",
    "토큰 ID를 만들려면 Vocabulary 구축이 필요함\n",
    "\n",
    "이때 Vocabulary는 알파벳 순서로 정렬되어 있음\n",
    "\n",
    "이전에 작업했던 preprocessed로 Vocabulary 사이즈를 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fde034b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1133\n"
     ]
    }
   ],
   "source": [
    "all_words = sorted(set(preprocessed))\n",
    "vocab_size = len(all_words)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5923c0b",
   "metadata": {},
   "source": [
    "Vocabulary를 만들고 처음부터 51개 항목 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f961985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('', 0)\n",
      "('\\n', 1)\n",
      "(' ', 2)\n",
      "('!', 3)\n",
      "('\"', 4)\n",
      "(\"'\", 5)\n",
      "('(', 6)\n",
      "(')', 7)\n",
      "(',', 8)\n",
      "('--', 9)\n",
      "('.', 10)\n",
      "(':', 11)\n",
      "(';', 12)\n",
      "('?', 13)\n",
      "('A', 14)\n",
      "('Ah', 15)\n",
      "('Among', 16)\n",
      "('And', 17)\n",
      "('Are', 18)\n",
      "('Arrt', 19)\n",
      "('As', 20)\n",
      "('At', 21)\n",
      "('Be', 22)\n",
      "('Begin', 23)\n",
      "('Burlington', 24)\n",
      "('But', 25)\n",
      "('By', 26)\n",
      "('Carlo', 27)\n",
      "('Chicago', 28)\n",
      "('Claude', 29)\n",
      "('Come', 30)\n",
      "('Croft', 31)\n",
      "('Destroyed', 32)\n",
      "('Devonshire', 33)\n",
      "('Don', 34)\n",
      "('Dubarry', 35)\n",
      "('Emperors', 36)\n",
      "('Florence', 37)\n",
      "('For', 38)\n",
      "('Gallery', 39)\n",
      "('Gideon', 40)\n",
      "('Gisburn', 41)\n",
      "('Gisburns', 42)\n",
      "('Grafton', 43)\n",
      "('Greek', 44)\n",
      "('Grindle', 45)\n",
      "('Grindles', 46)\n",
      "('HAD', 47)\n",
      "('Had', 48)\n",
      "('Hang', 49)\n",
      "('Has', 50)\n"
     ]
    }
   ],
   "source": [
    "vocab = {token:integer for integer, token in enumerate(all_words)}\n",
    "for i, item in enumerate(vocab.items()):\n",
    "    print(item)\n",
    "    if i>= 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a6b69a",
   "metadata": {},
   "source": [
    "위의 출력 결과는 개별 토큰과 고유한 정수 레이블을 담고 있음\n",
    "\n",
    "\n",
    "______\n",
    "\n",
    "<아래코드>\n",
    "LLM의 출력은 기본적으로 숫자로 되어있는데 이를 다시 텍스트로 바꾸는 작업이 필요함\n",
    "\n",
    "->Inverse vocabulary가 필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "434a9cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    #self는 \n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        #inverse vocabular 만들기  \n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    #input text -> token ID\n",
    "    def encode(self, text):\n",
    "        #텍스트를 토큰 단위로 쪼갬 + strip으로 공백제거\n",
    "        preprocessed = re.split(r'([,.;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        '''\n",
    "        ids = []\n",
    "        for s in preprocess:\n",
    "        ids.append(self.str_to_int[s])\n",
    "        ''' \n",
    "        #바로 위에 코드에서 vocab = {token: integer for integer, token in enumerate(all_words)}로 토큰ID를 이미 시켰음\n",
    "        #enumerate로 이미 토큰화가 부여된 상태임\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "\n",
    "    #Token ID -> Text\n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i] for i in ids])\n",
    "        '''\n",
    "        tokens = []\n",
    "        for i in ids:               # ids 리스트 안의 숫자를 하나씩 꺼냄\n",
    "        token = self.int_to_str[i]   # 숫자를 문자열 토큰으로 변환\n",
    "        tokens.append(token)         # tokens 리스트에 넣음\n",
    "        '''\n",
    "        #문장 부호만 남기고 공백은 삭제하기\n",
    "        #r'\\1'는 \n",
    "        text = re.sub(r'\\s+([,.?\"()\\'])', r'\\1', text)\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f361315b",
   "metadata": {},
   "source": [
    "위에서 만든것을 \n",
    "새로운 text내용으로 Tokenizing 실행\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d61320e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 5, 853, 991, 605, 536, 749, 8, 1129, 599, 8, 70, 10, 41, 854, 1111, 757, 796, 10]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"It's the last he painted, you know,\n",
    "         Mrs.Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af3ba9e",
   "metadata": {},
   "source": [
    "출력 결과는 아래 코드로 다시 복구 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10148f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It' s the last he painted, you know, Mrs. Gisburn said with pardonable pride.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7e8706",
   "metadata": {},
   "source": [
    "만약 아래와 같은 문장을 수행하면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "887e369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전체 실행을 위해 주석처리\n",
    "#text = \"Hello, do you like tea?\"\n",
    "#print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41c9fe",
   "metadata": {},
   "source": [
    "버그가 발생함 -> 위의 dataset에는 Hello라는 단어가 없음. ->Out of Vocabulary문제가 발생함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8729051",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "Section 2.4\n",
    "------------\n",
    "위에서 발생한 OOV문제를 해결하려면 Tokneizer를 수정해야함\n",
    "\n",
    "예시로 토큰 2개를 추가: <|unk|>와 <|endoftext|>\n",
    "\n",
    "<|unk|>: 모르는 단어를 만났을때 사용하도록 함\n",
    "\n",
    "<|endoftext|>:  문서나 책 앞에 추가함(텍스트가 연결이 되어있으나, 관련이 없다는 것을 알려줌)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944ad39d",
   "metadata": {},
   "source": [
    "아래의 코드로 토큰을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "372fed7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1135\n"
     ]
    }
   ],
   "source": [
    "all_tokens = sorted(list(set(preprocessed)))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])\n",
    "vocab = {token:integer for integer,token in enumerate(all_tokens)}\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8177e4d",
   "metadata": {},
   "source": [
    "실제로 추가되었는지 확인하기 위해 Vocabulary의 마지막 5개 단어 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de7eac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1130)\n",
      "('your', 1131)\n",
      "('yourself', 1132)\n",
      "('<|endoftext|>', 1133)\n",
      "('<|unk|>', 1134)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126cbf45",
   "metadata": {},
   "source": [
    "위에서 추가한 토큰을 바탕으로 알지못하는 단어를 만났을떄 \n",
    "<|unk|>토큰을 사용하도록 코드를 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4c22e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab\n",
    "        self.int_to_str = {i:s for s,i in vocab.items()}\n",
    "\n",
    "    def encode(self, text):\n",
    "        preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [\n",
    "            item.strip() for item in preprocessed if item.strip()\n",
    "        ]\n",
    "        #모르는 단어를 만났을때 <|unk|>토큰으로 바꾸기\n",
    "        preprocessed = [item if item in self.str_to_int\n",
    "                        else \"<|unk|>\" for item in preprocessed]\n",
    "        \n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        text = \" \".join([self.int_to_str[i]for i in ids])\n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce759085",
   "metadata": {},
   "source": [
    "텍스트가 끝났을때 <|endoftext|>를 사용하도록함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "816f7f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello, do you like tea?<|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \" Hello, do you like tea?\"\n",
    "text2 = \" In the sunlit terraces of the palace.\"\n",
    "text = \"<|endoftext|>\".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6679e288",
   "metadata": {},
   "source": [
    "위의 출력 결과를 보면 <|endoftext|>가 사용된 모습을 확인 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6740d843",
   "metadata": {},
   "source": [
    "위에서 추가한 토큰을 적용해 다시 토큰화 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3621601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1134, 8, 358, 1129, 631, 978, 13, 1133, 58, 991, 959, 987, 725, 991, 1134, 10]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb831225",
   "metadata": {},
   "source": [
    "아래의 코드로 실제 토큰이 잘 추가 되었는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6b7223a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9467b9d8",
   "metadata": {},
   "source": [
    "위에서는 버그가 나왔던 Hello가 지금은 <|unk|>로 대체되어 버그 없이 잘 실행됨\n",
    "\n",
    "여기에서 사용된 특수 토큰 외에 다른 토큰들에는\n",
    "\n",
    "[BOS]: Beginning of sequence - 텍스트의 시작 부분 표시\n",
    "\n",
    "[EOS]: End of sequence -  텍스트의 끝에 위치 e.g. 서로다른 문서와 책을 합칠 경우 사용\n",
    "\n",
    "[PAD]: Padding - 토큰을 사용해 batch에서 가장 긴 텍스트 길이까지 확장할때 사용\n",
    "\n",
    "그런데 GPT에서는 <|endoftext|>만 사용하며 <|unk|>도 사용 안함\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431c799",
   "metadata": {},
   "source": [
    "Section2.5\n",
    "---------\n",
    "BPE(Byte Pair Encoding)을 사용하기 위해 tiktoken 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3c702dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tiktoken in c:\\users\\user\\anaconda3\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken) (2024.9.11)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tiktoken) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pip install tiktoken\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4609e3d0",
   "metadata": {},
   "source": [
    "tiktoken을 사용해서 이전에 사용한 구문 encode해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bb37700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271]\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "#BPE토크나이저 초기화\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = (\n",
    "    \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    "    \"of someunknownPlace\"\n",
    ")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117498ad",
   "metadata": {},
   "source": [
    "다시 decode를 사용해서 복구도 할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7cdd181b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace\n"
     ]
    }
   ],
   "source": [
    "strings= tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e61cccb",
   "metadata": {},
   "source": [
    "만약 모르는 단어가 나온다면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5be29fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16012, 71, 506, 1855]\n",
      "Sunhong Min\n"
     ]
    }
   ],
   "source": [
    "text = \"Sunhong Min\"\n",
    "praticeEncoder = tokenizer.encode(text)\n",
    "print(praticeEncoder)\n",
    "praticeDecoder = tokenizer.decode(praticeEncoder)\n",
    "print(praticeDecoder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249880f",
   "metadata": {},
   "source": [
    "위는 encode 아래는 decode 출력결과인데 사전에 없는 단어로도 잘 나오는 모습을 볼 수 있음\n",
    "\n",
    "BPE Tokenizer는 <|unk|> 토큰을 안쓰는데도 someunknownPlace처럼 모르는 단어를 인코딩, 디코딩을 잘함 \n",
    "\n",
    "모르는 단어를 개별 문자나 부분 단어로 토큰화해서 모든 텍스트를 처리 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9717c398",
   "metadata": {},
   "source": [
    "______\n",
    "책에서 설명하는 BPE는 개별 문자 e.g \"a\", \"b\"를 Vocabulary에 추가하고 자주 등장하는 단어끼리 합침\n",
    "\n",
    "e.g. define, depend .. 처럼 de가 자주 등장하면 de로 합침 .. \n",
    "\n",
    "합치는 기준은 determined by a frequency cutoff 라고함\n",
    "\n",
    "추가설명은 ppt\n",
    "_____\n",
    "Section2.6\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b8e287",
   "metadata": {},
   "source": [
    "LLM은 다음 단어를 예측하는 식으로 훈련됨 ->Sliding window사용\n",
    "\n",
    "​\n",
    "\n",
    "BPE토크나이저로 \"the Verdict\"전체 토큰화 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31754e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85612301",
   "metadata": {},
   "source": [
    "실행하면 5145가 나오는데  훈련세트에 있는 총 토큰 개수 출력한 것임\n",
    "\n",
    "more interesting text passage in the next steps하기 위해서 처음 50개 토큰을 삭제한다고 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59593023",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd3d728",
   "metadata": {},
   "source": [
    "다음 단어 예측(input- target)을 만들기 위해서 x, y변수를 사용함\n",
    "\n",
    "x: 입력 토큰 담기\n",
    "\n",
    "y: 토큰 하나만큼 이동한 타깃 담기\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea590b",
   "metadata": {},
   "source": [
    "단순히 y가 x보다 한 칸 더 window를 이동시킨 것을 출력하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97d1869b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [290, 4920, 2241, 287]\n",
      "y        [4920, 2241, 287, 257]\n"
     ]
    }
   ],
   "source": [
    "context_size = 4\n",
    "x = enc_sample[:context_size]\n",
    "y = enc_sample[1:context_size+1]\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y        {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade63860",
   "metadata": {},
   "source": [
    "___\n",
    "화살표 왼쪽: LLM이 입력 받은 값\n",
    "\n",
    "화살표 오른쪽: LLM이 예측해야 할 토큰 ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50aa81c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[290] ----> 4920\n",
      "[290, 4920] ----> 2241\n",
      "[290, 4920, 2241] ----> 287\n",
      "[290, 4920, 2241, 287] ----> 257\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(context, \"---->\", desired)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55847932",
   "metadata": {},
   "source": [
    "토큰ID를 Text로 바꾸기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "514c22c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " and ---->  established\n",
      " and established ---->  himself\n",
      " and established himself ---->  in\n",
      " and established himself in ---->  a\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, context_size+1):\n",
    "    context = enc_sample[:i]\n",
    "    desired = enc_sample[i]\n",
    "    print(tokenizer.decode(context), \"---->\", tokenizer.decode([desired]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ab3043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\user\\anaconda3\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d9404c",
   "metadata": {},
   "source": [
    "토큰 -> 임베딩 변환을 위해 데이터 로더 구현 필요\n",
    "\n",
    "데이터로더: input data를 순회하며 input과 target을  pytorch tensor로 tensor반환\n",
    "\n",
    "e.g. tensor x,y 가 있다고 하면\n",
    "\n",
    "tensor x: 입력을 모아둠\n",
    "\n",
    "tensor y: predict target을 모아둠"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c641e08",
   "metadata": {},
   "source": [
    "dataset class를 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f233c9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GPTDatabaseV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        #전체 텍스트 토큰화\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            #input 시퀀스\n",
    "            input_chunk = token_ids[i:i + max_length]\n",
    "            #정답 시퀀스 - input보다 한 칸 오른쪽으로 이동\n",
    "            target_chunk = token_ids[i + 1: i + max_length+1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "    \n",
    "\n",
    "    #데이터셋에 있는 전체 행 수를 반환\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    #데이터셋에서 하나의 행을 반환\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da7134b",
   "metadata": {},
   "source": [
    "input -target pair의 batch를 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79820866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
    "                         stride = 128, \n",
    "                         shuffle=True, \n",
    "                         #drop_last를 True로 둠\n",
    "                         #전체 Data size를 batch_size로 나누었을때 마지막에 안나누어 떨어지는 batch를 버림\n",
    "                         drop_last = True,\n",
    "                         num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatabaseV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d1d6a8",
   "metadata": {},
   "source": [
    "이후 max_lenght=4로 batch_size = 1로 잘 작동하는지 확인하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a71a6c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding='utf-8')as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=1, max_length=4, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb765e8",
   "metadata": {},
   "source": [
    "첫번째 tensor는 input token ID를 저장, 두 번째 텐서는 target token ID를 저장\n",
    "\n",
    "현재 max_length는 4인데, 보통 256을 사용함\n",
    "\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9654b9e8",
   "metadata": {},
   "source": [
    "pratice problem)max_length와 stride의 크기 변경해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e0b325d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[   40,   367,  2885],\n",
      "        [  367,  2885,  1464],\n",
      "        [ 2885,  1464,  1807],\n",
      "        [ 1464,  1807,  3619],\n",
      "        [ 1807,  3619,   402],\n",
      "        [ 3619,   402,   271],\n",
      "        [  402,   271, 10899],\n",
      "        [  271, 10899,  2138],\n",
      "        [10899,  2138,   257],\n",
      "        [ 2138,   257,  7026],\n",
      "        [  257,  7026, 15632],\n",
      "        [ 7026, 15632,   438],\n",
      "        [15632,   438,  2016],\n",
      "        [  438,  2016,   257],\n",
      "        [ 2016,   257,   922],\n",
      "        [  257,   922,  5891],\n",
      "        [  922,  5891,  1576],\n",
      "        [ 5891,  1576,   438],\n",
      "        [ 1576,   438,   568]]), tensor([[  367,  2885,  1464],\n",
      "        [ 2885,  1464,  1807],\n",
      "        [ 1464,  1807,  3619],\n",
      "        [ 1807,  3619,   402],\n",
      "        [ 3619,   402,   271],\n",
      "        [  402,   271, 10899],\n",
      "        [  271, 10899,  2138],\n",
      "        [10899,  2138,   257],\n",
      "        [ 2138,   257,  7026],\n",
      "        [  257,  7026, 15632],\n",
      "        [ 7026, 15632,   438],\n",
      "        [15632,   438,  2016],\n",
      "        [  438,  2016,   257],\n",
      "        [ 2016,   257,   922],\n",
      "        [  257,   922,  5891],\n",
      "        [  922,  5891,  1576],\n",
      "        [ 5891,  1576,   438],\n",
      "        [ 1576,   438,   568],\n",
      "        [  438,   568,   340]])]\n"
     ]
    }
   ],
   "source": [
    "def create_dataloader_pratice(txt, batch_size=4, max_length=256,\n",
    "                         stride = 2, \n",
    "                         shuffle=True, \n",
    "                         drop_last = True,\n",
    "                         num_workers = 0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatabaseV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last = drop_last,\n",
    "        num_workers = num_workers\n",
    "    )\n",
    "\n",
    "    return dataloader_pratice\n",
    "\n",
    "with open(\"the-verdict.txt\", \"r\", encoding='utf-8')as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "dataloader_pratice = create_dataloader_v1(\n",
    "    raw_text, batch_size=19, max_length=3, stride=1, shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader_pratice)\n",
    "first_batch = next(data_iter)\n",
    "print(first_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8312646",
   "metadata": {},
   "source": [
    "____\n",
    "batch_size>1일 경우 샘플링하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0e33982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      " Target: tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=4, stride=4,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Input: \", inputs)\n",
    "print(\"\\n Target:\", targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4835eb",
   "metadata": {},
   "source": [
    "Cf) batch_size에 중첩이 있으면 과적합이 생길 가능성이 있음\n",
    "\n",
    "윈도우 1: [1,2,3,4]\n",
    "윈도우 2:   [2,3,4,5]\n",
    "윈도우 3:     [3,4,5,6]\n",
    "각 시퀀스가 75%이상 겹침 -> 중복되는 문장을 반복적으로 학습하게됨 ->Overfitting\n",
    "_____\n",
    "Section2.7\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2633ff",
   "metadata": {},
   "source": [
    "Input token이 4개 있다고 가정 후 임베딩층 가중치 행렬 추가하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c7dbe487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(embedding_layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a883f",
   "metadata": {},
   "source": [
    "가중치 행렬은 랜덤한 값을 갖고 있는데, 이는 LLM훈련할때 최적화됨\n",
    "\n",
    "위에 코드에서 보면 \n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "으로 설정했는데 이때문에 행이6개 열이3개가 나옴\n",
    "\n",
    "위의 코드를 토큰 ID에 적용하면\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e064441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4015,  0.9666, -1.1481]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(torch.tensor([3])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a2626",
   "metadata": {},
   "source": [
    "tensor의 4번째 행과 동일한 결과가 나옴.\n",
    "\n",
    "->embedding layer는 토큰ID를 기반으로 weight tensor에서 행을 추출함\n",
    "\n",
    "​"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed7c11e",
   "metadata": {},
   "source": [
    "위에서 입력한 4개의 input id를 모두 적용하면 아래의 결과가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4eb75ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d13b540",
   "metadata": {},
   "source": [
    "사전 정의된 Vocabulary(dataset)에서 필요한 행만 뽑아서 토큰 임베딩 결과를 만든다\n",
    "\n",
    "​\n",
    "\n",
    "cf) 데이터셋 = 해리포터안에 있는 단어를 토큰화 - > 임베딩을 시킴\n",
    "\n",
    "근데 새로운 단어 fox jmps over dog라는 문장 있다고 가정\n",
    "\n",
    "-> 해리포터에서 저 단어4개가 이미 토큰화가 되었을거임\n",
    "\n",
    "-> fox jumps over dog에 알맞는 토큰값을 해리포터 Vocabulary dictionary에서 찾음\n",
    "\n",
    "-> fox jumps over dog에맞는 토큰id를 얻게됨\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73829385",
   "metadata": {},
   "source": [
    "Section2.8\n",
    "-------\n",
    "\n",
    "\n",
    "LLM은 위치에 대한 개념이 없음 정확하게는 self-attention에게 없음\n",
    "\n",
    "​\n",
    "\n",
    "cf)Attention is all you need 논문에서는 삼각함수로 positional encoding을 진행함\n",
    "PPT설명: positional? +  positional encoding이 필요한 이유?\n",
    "\n",
    "​\n",
    "\n",
    "Positional Encoding은 상대적인 위치임 ->멀리 떨어져 있는 정도로 관계를 학습\n",
    "\n",
    "->일반화에 좋음\n",
    "\n",
    "​\n",
    "\n",
    "50257크기의 Vocabulary dictionary로 BPE토크나이저 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3beb975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4f063f",
   "metadata": {},
   "source": [
    "​\n",
    "\n",
    "샘플링한 각 배치에 있는 토큰 ID를 256차원 벡터로 임베딩\n",
    "\n",
    "if) batchsize:8, token:4일경우 8 * 4 * 256 tensor가 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "90380194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID:  tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "\n",
      " Inputsize:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False\n",
    ")\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"Token ID: \", inputs)\n",
    "print(\"\\n Inputsize:\\n\", inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b240b5",
   "metadata": {},
   "source": [
    "여기서 torch.Size가([8, 4])인데 batch에 4개의 토큰을 가진 text sample 8개가 들어있다는 의미임\n",
    "\n",
    "batch 1 step을 보여줌\n",
    "_______"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab37425",
   "metadata": {},
   "source": [
    "임베딩 층을 사용해 토큰 ID를 256차원 벡터로 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0de952f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7514f8",
   "metadata": {},
   "source": [
    "위의 출력 결과는\n",
    "\n",
    "([batch_size, sequence length(max_length), embedding dimension\n",
    "\n",
    "을 나타냄\n",
    "\n",
    "-> 이는 각 토큰ID가 256차원 벡터로 임베딩 된 것을 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcce9ee",
   "metadata": {},
   "source": [
    "___________\n",
    "GPT의 절대 임베딩 \n",
    "\n",
    "-> token_embedding_layer와 동일한 임베딩 차원을 가지는 또다른 임베딩 층을 만들면 됨\n",
    "\n",
    "GPT계열 모델은 2종류의 임베딩을 더해서 최종 입력 벡터를 만들음\n",
    "\n",
    "token embedding과 absolute positional embedding\n",
    "\n",
    "두 임베딩을 더해야하기때문에 두 차원이 동일해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac0e9197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "context_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(context_length))\n",
    "print(pos_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab6d337",
   "metadata": {},
   "source": [
    "위의 출력 결과는\n",
    "\n",
    "[(sequence length, embedding dimension)]\n",
    "\n",
    "을 의미함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a33d19",
   "metadata": {},
   "source": [
    "_______\n",
    "\n",
    "둘이 더하면 positional embedding 끝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fdfd83f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b8c72",
   "metadata": {},
   "source": [
    "Chapter3\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09e99f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    "    [[0.43, 0.15, 0.89], #Your (x^1)\n",
    "    [0.55, 0.87, 0.66], #journey (x^2)\n",
    "    [0.57, 0.85, 0.64], #starts (x^3)\n",
    "    [0.22, 0.58, 0.33], #with (x^4)\n",
    "    [0.77, 0.25, 0.10], #one (x^]5)\n",
    "    [0.05, 0.80, 0.55]] #step (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72ba5442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "attn_score_2 = torch.empty(inputs.shape[0])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_score_2[i] = torch.dot(x_i, query)\n",
    "print(attn_score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42158ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weight:  tensor([0.1455, 0.2278, 0.2249, 0.1285, 0.1077, 0.1656])\n",
      "Sum:  tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "attn_weight_2_tmp = attn_score_2 / attn_score_2.sum()\n",
    "print(\"Attention Weight: \", attn_weight_2_tmp)\n",
    "print(\"Sum: \", attn_weight_2_tmp.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "038fb822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention weight:  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "def softmax_naive(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum(dim = 0)\n",
    "\n",
    "attn_weight_2_naive = softmax_naive(attn_score_2)\n",
    "print(\"attention weight: \", attn_weight_2_naive)\n",
    "print(\"Sum: \", attn_weight_2_naive.sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "af2a4512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention weight:  tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "sum:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "attn_weight_2 = torch.softmax(attn_score_2, dim = 0)\n",
    "print(\"attention weight: \", attn_weight_2)\n",
    "print(\"sum: \", attn_weight_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0aa7514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weight_2[i]*x_i\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63224a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_score = torch.empty(6,6)\n",
    "for i, x_i in enumerate(inputs):\n",
    "    for j, x_j in enumerate(inputs):\n",
    "        attn_score[i,j] = torch.dot(x_i, x_j)\n",
    "print(attn_score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8645b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])\n"
     ]
    }
   ],
   "source": [
    "attn_scores = inputs @ inputs.T\n",
    "print(attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bbf5f7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 6])\n",
      "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n"
     ]
    }
   ],
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim = -1)\n",
    "print(attn_scores.shape)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e35c1d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2번째 행의 합:  1.0\n",
      "모든 행의 합:  tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "row_2_sum = sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
    "print(\"2번째 행의 합: \", row_2_sum)\n",
    "print(\"모든 행의 합: \", attn_weights.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5fe74028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]])\n"
     ]
    }
   ],
   "source": [
    "all_context_vecs = attn_weights @ inputs\n",
    "print(all_context_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1556cea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.1 row2 context vector:  tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "print(\"3.3.1 row2 context vector: \", context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0300683",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2번째 입력 원소\n",
    "x_2 = inputs[1]\n",
    "#input embedding size, d_in = 3\n",
    "d_in = inputs.shape[1]\n",
    "#output embedding size, d_out = 2\n",
    "d_out = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "60a7fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "#requires_grad: backpropagation의 수행 여부\n",
    "#실제 훈련시에는 True로 지정 -> weight mat 업데이트\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key\t= torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value\t= torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae5696bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "query_2 = x_2 @ W_query\n",
    "key_2 = x_2 @ W_key\n",
    "value_2 = x_2 @ W_value\n",
    "print(query_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb176aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape:  torch.Size([6, 2])\n",
      "values.shape:  torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "keys = inputs @ W_key\n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape: \", keys.shape)\n",
    "print(\"values.shape: \", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "10074ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.8524)\n"
     ]
    }
   ],
   "source": [
    "keys_2 = keys[1]\n",
    "attn_score_22 = query_2.dot(keys_2)\n",
    "print(attn_score_22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10fe0795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "attn_scores_2 = query_2 @ keys.T\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a05b61bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "d_k = keys.shape[-1]\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / d_k**0.5, dim =-1)\n",
    "print(attn_weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aabf5f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3069, 0.8188])\n"
     ]
    }
   ],
   "source": [
    "context_vec_2 = attn_weight_2 @ values \n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "204e0174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class SelfAttention_v1(nn.Module):\n",
    "\tdef __init__(self, d_in, d_out):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.W_query = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\t\tself.W_key \t = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\t\tself.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        \n",
    "\tdef forward(self,x):\n",
    "\t\tkeys= x @ self.W_key\n",
    "\t\tqueries = x @ self.W_query\n",
    "\t\tvalues = x @ self.W_value\n",
    "\t\tattn_scores = queries @ keys.T #omega\n",
    "\t\tattn_weights = torch.softmax(\n",
    "\t\t\tattn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "\t\t)\n",
    "\t\tcontext_vec = attn_weights @ values\n",
    "\t\treturn context_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe6dc37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttention_v1(d_in, d_out)\n",
    "print(sa_v1(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc667781",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias = False):\n",
    "        super(). __init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key \t = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "            attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec\n",
    "           \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ad094bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9eba694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs)\n",
    "keys = sa_v2.W_key(inputs)\n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b5da1487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "context_length = attn_scores.shape[0]\n",
    "#trill은 lower triangle = 대각선보다 위쪽을 0으로 만들음\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))\n",
    "print(mask_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d8ee4966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2041, 0.1659, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2036, 0.1659, 0.1662, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "masked_simple = attn_weights * mask_simple\n",
    "print(masked_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "95db280b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(masked_simple_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f15064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#diagonal=1 주대각선보다 한 칸 위를 -inf로 설정\n",
    "mask = torch.triu(torch.ones(context_length, context_length),diagonal=1)\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)\n",
    "print(masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec118cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#마스킹된 결과에 softmax 적용\n",
    "#shape[-1] : 텐서의 마지막 축 크기\n",
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7475c347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1855, 0.8812],\n",
      "        [0.2795, 0.9361],\n",
      "        [0.3133, 0.9508],\n",
      "        [0.2994, 0.8595],\n",
      "        [0.2702, 0.7554],\n",
      "        [0.2772, 0.7618]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#컨텍스트 벡터 출력하기\n",
    "context_vec = attn_weights @ values\n",
    "print(context_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc07f2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 0., 2., 2., 0.],\n",
      "        [0., 0., 0., 2., 0., 2.],\n",
      "        [2., 2., 2., 2., 0., 2.],\n",
      "        [0., 2., 2., 0., 0., 2.],\n",
      "        [0., 2., 0., 2., 0., 2.],\n",
      "        [0., 2., 2., 2., 2., 0.]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "dropout = torch.nn.Dropout(0.5)\n",
    "example = torch.ones(6,6)\n",
    "print(dropout(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "86e4eecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7599, 0.6194, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.4921, 0.4925, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3966, 0.0000, 0.3775, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.3331, 0.3084, 0.3331, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d69e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
